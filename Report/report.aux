\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{kylberg2011virus}
\citation{kylberg2011virus}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Dataset}{1}{section.2}}
\newlabel{text:dataset}{{2}{1}{Dataset}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related Work}{1}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Local Binary Profile (LBP)}{1}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of LBP sampling: The green points are the neighbouring sample points at distance $r$ from the central white point. In this case, we are sampling with $n=8$ neighbour points.\relax }}{1}{figure.1}}
\newlabel{fig:lbp_basic}{{1}{1}{Example of LBP sampling: The green points are the neighbouring sample points at distance $r$ from the central white point. In this case, we are sampling with $n=8$ neighbour points.\relax }{figure.1}{}}
\citation{kylberg2011virus}
\citation{maenpaa2003multi}
\citation{kylberg2011virus}
\citation{kylberg2011virus}
\citation{maenpaa2003multi}
\citation{maenpaa2003multi}
\citation{kylberg2011virus}
\citation{kylberg2011virus}
\citation{kylberg2011virus}
\citation{kylberg2011virus}
\citation{kylberg2011virus}
\@writefile{toc}{\contentsline {paragraph}{Rotational Invariant LBP}{2}{figure.1}}
\@writefile{toc}{\contentsline {paragraph}{Uniform LBP}{2}{figure.1}}
\@writefile{toc}{\contentsline {paragraph}{Gaussian Filtered LBP}{2}{figure.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of LBPF sampling: In the simple LBP, the points would be sampled at equal distances around the dotted circles for one radius as in figure \ref  {fig:lbp_basic} but with this extension, the points are sampled according to a Gaussian distribution inside the solid black circles at multiple radii. In this picture, the number of neighbours also vary with the radii. This image comes from \citet  {maenpaa2003multi}.\relax }}{2}{figure.2}}
\newlabel{fig:lbpf}{{2}{2}{Example of LBPF sampling: In the simple LBP, the points would be sampled at equal distances around the dotted circles for one radius as in figure \ref {fig:lbp_basic} but with this extension, the points are sampled according to a Gaussian distribution inside the solid black circles at multiple radii. In this picture, the number of neighbours also vary with the radii. This image comes from \citet {maenpaa2003multi}.\relax }{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Radial Density Profile (RDP)}{2}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Example of RDP sampling: The green zone is the set of sampled pixels for a given radius $r$.\relax }}{2}{figure.3}}
\newlabel{fig:rdp}{{3}{2}{Example of RDP sampling: The green zone is the set of sampled pixels for a given radius $r$.\relax }{figure.3}{}}
\citation{kylberg2011virus}
\citation{kylberg2011virus}
\citation{kylberg2011virus}
\citation{Bastien-Theano-2012,bergstra+al:2010-scipy}
\citation{coelho2012mahotas}
\citation{kylberg2011virus}
\@writefile{toc}{\contentsline {paragraph}{Fourier RDP}{3}{figure.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Results}{3}{subsection.3.3}}
\newlabel{text:relwork_results}{{3.3}{3}{Results}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Neural Networks Approach}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Results}{3}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Discussion}{3}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces This figure comes from \citet  {kylberg2011virus}. The classification errors are shown for a Random Forest classifier using the 6 different texture extractors as described in section \ref  {text:relwork_results}. The boxes' vertical lines represent the median and the red $\times $ represent outliers that are at least 1.5 times the size of the box away from it. The error bars are from the lower to the upper quartile.\relax }}{4}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:relwork_results}{{4}{4}{This figure comes from \citet {kylberg2011virus}. The classification errors are shown for a Random Forest classifier using the 6 different texture extractors as described in section \ref {text:relwork_results}. The boxes' vertical lines represent the median and the red $\times $ represent outliers that are at least 1.5 times the size of the box away from it. The error bars are from the lower to the upper quartile.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Learning curves for a feed-forward neural network with one hidden layer of 256 units.\relax }}{4}{figure.caption.2}}
\newlabel{shrine0_curves}{{5}{4}{Learning curves for a feed-forward neural network with one hidden layer of 256 units.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Confusion Matrices for a feed-forward neural network with one hidden layer of 256 unit.\relax }}{5}{figure.caption.3}}
\newlabel{shrine0_mat}{{6}{5}{Confusion Matrices for a feed-forward neural network with one hidden layer of 256 unit.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Learning curves for a feed-forward neural network with two hidden layers of 256 units each.\relax }}{5}{figure.caption.4}}
\newlabel{shrine0_curves}{{7}{5}{Learning curves for a feed-forward neural network with two hidden layers of 256 units each.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confusion Matrices for a feed-forward neural network with two hidden layers of 256 units each.\relax }}{6}{figure.caption.5}}
\newlabel{shrine0_mat}{{8}{6}{Confusion Matrices for a feed-forward neural network with two hidden layers of 256 units each.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Learning curves for a feed-forward neural network with three hidden layers of 256, 128, 64 units.\relax }}{6}{figure.caption.6}}
\newlabel{shrine0_curves}{{9}{6}{Learning curves for a feed-forward neural network with three hidden layers of 256, 128, 64 units.\relax }{figure.caption.6}{}}
\bibdata{ref}
\bibcite{Bastien-Theano-2012}{{1}{2012}{{Bastien et~al.}}{{Bastien, Lamblin, Pascanu, Bergstra, Goodfellow, Bergeron, Bouchard, and Bengio}}}
\bibcite{bergstra+al:2010-scipy}{{2}{2010}{{Bergstra et~al.}}{{Bergstra, Breuleux, Bastien, Lamblin, Pascanu, Desjardins, Turian, Warde-Farley, and Bengio}}}
\bibcite{coelho2012mahotas}{{3}{2012}{{Coelho}}{{}}}
\bibcite{kylberg2011virus}{{4}{2011}{{Kylberg et~al.}}{{Kylberg, Uppstr{\"o}m, and Sintorn}}}
\bibcite{maenpaa2003multi}{{5}{2003}{{M{\"a}enp{\"a}{\"a} and Pietik{\"a}inen}}{{}}}
\bibstyle{plainnat}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Confusion Matrices for a feed-forward neural network with three hidden layers of 256, 128, 64 units.\relax }}{7}{figure.caption.7}}
\newlabel{shrine0_mat}{{10}{7}{Confusion Matrices for a feed-forward neural network with three hidden layers of 256, 128, 64 units.\relax }{figure.caption.7}{}}
