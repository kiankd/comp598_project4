\input{./preamble.tex}
\input{./title.tex}
\linespread{1.05}
\usepackage{lipsum}
\usepackage{multicol}
\usepackage{alltt}
\usepackage[margin=1in]{geometry}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{paralist}
\usepackage{float}
\usepackage{microtype}
\usepackage{abstract}
\usepackage[utf8]{inputenc}
\usepackage[numbers]{natbib}
\usepackage{graphicx}
\renewcommand{\abstractnamefont}{\large\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\itshape} % Set the abstract itself to small italic text
\usepackage{lettrine}
\usepackage{tabulary}
\usepackage{import}
\usepackage{makecell}
\usepackage{enumitem}
\usepackage{paralist}
\usepackage{pgf}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{cite}
\def\UrlBreaks{\do-}


\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}

\usepackage{titlesec} % Allows customization of titles
%\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
%\renewcommand\thesubsection{\Roman{subsection}} % Roman numerals for subsections
\titleformat{\section}[block]{\Large\scshape\centering\bfseries}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large\bfseries}{\thesubsection.}{1em}{} % Change the look of the section titles

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer
\fancyhead[C]{Virus Classification from Transmission Electron Microscopy $\bullet$ Fall 2015} % Custom header text
\fancyfoot[RO,LE]{\thepage} % Custom footer text

\title{\fontsize{18pt}{10pt}\textbf{Classifiying Transmission Electron Microscopy Virus Textures}} % Article title

% \author{
% \large{Alan Do-Omri}\\[2mm] % Your name
% \normalsize McGill University \\ % Your institution
% \normalsize \href{mailto:alan.do-omri@mail.mcgill.ca}{alan.do-omri@mail.mcgill.ca}}

\author{
\large{Alan Do-Omri}\\[2mm] 
\normalsize 260532985 \\ 
\and 
\large{Kian Kenyon-Dean}\\[2mm]
\normalsize 260564475 \\
\and
\large{Genevieve Fried}\\[2mm]
\normalsize 260564432 \\
}


\begin{document}

\maketitle

\begin{abstract}
On a daily basis doctors are tasked with determining the identity of viruses from blood samples. Even with advanced microscopy techniques, viral strains can be difficult to discern with the human eye. Misclassification of viruses can have grave implications, not only for the patients in question but also for those who come into contact with him or her, so it is a critical problem demanding high accuracy. Fortunately, virus classification can be an image classification problem, and machine learning methods present exceedingly high accuracy rates for image classification tasks without requiring expert knowledge to do so. Here we present a successful application of Convolutional Neural Networks (CNN) to the problem of virus classification. Using the Virus Texture Dataset from Uppsala University, we classify viruses samples into one of 15 categories and compare its performance to previous work done on the same task.

\end{abstract} 
\vspace{0.5cm}

\begin{multicols}{2}
\section{Introduction}
Identifying viral pathogens, existing and emerging, is a critical priority for public health. Current diagnostic methods include direct examination of a speciman by an trained medical professional using Electron Microscopy methods. Unfortunately, even with magnification techniques it can be difficult for doctors to identify specific viral types. 

On the other hand, automatic classification methods in machine learning have proven quite successful at image classification. In particular, research employing neural networks has reshaped image classification in recent years \citet{Juergen_2015}. Specifically, Max Pooling Convolutional Neural Networks have set the bar at it's highest for an array of tasks, including the multi-digit number recognition in Google Street View images, reCAPTCHA box classification \citet{DBLP:journals/corr/GoodfellowBIAS13}, and ImageNet classification \citet{NIPS2012_4824}. 

The high degree of accuracy obtained with these automated methods is highly desirable for a problem like virus classification. We utilize state-of-the-art machine learning methods for image processing by treating virus classification as an image classification problem. Our dataset is the Virus Texture Dataset from Uppsala University that contains images of fifteen different virus types; we extend the dataset with random rotations of the images. 

We experiment with an array of machine learning classifiers, including Support Vector Machines with linear and radial basis function kernels, Gaussian Naive Bayes, Logistic Regression, Random Forest Trees and Feed Forward Neural Networks with local binary pattern feature extractors. Our best results come from our Convolutional Neural Network (CNN) using max pooling, with which we classify virus samples from our dataset into one of 15 categories with an accuracy of approximately 85\%.

\section{Problem Definition}

Our research takes place in a greater context of a desire to use machine learning classification methods to accurately classify viruses from viral sample images. This extends to both viruses which are currently known, and potentially evolved viruses like the H1N1 influenza pandemic virus in Mexico and the US in 2009, which was a modified version of known influenza strains. Convolutional Neural Networks with all the function approximation power of Neural Networks, but specifically architected for images, present a highly promising solution for computer automated virus identification, and a useful supplementation to traditional virology research. 

From our survey of the work done in virus classification, treating virus classification as an image classification problem is not common. Most researchers have used Support Vector Machines, tree modeling structures like Random Forests, and Feed Forward Neural Networks to classify and predict known and emerging viral strains through analysis of genome segments and genetic sequences \citet{work_A} \citet{work_B} \citet{work_C}. \citet{kylberg2011virus}'s paper, which we looked to for insight into feature extraction methods, uses a Random Forest classifier to assess the discriminant potential of various texture measures on virus images. As far as we can tell, using a CNN is rather unprecedented for this problem. Thus we find the application of CNNs to virus classification a pertinent one that would be fruitful to explore further.


\section{Related Work}
\label{text:relwork_results}
In the work of \citet{kylberg2011virus}, texture analysis is performed on 15 different virus samples and the resulting feature vector is fed into a Random Forest classifier. The authors first compare the performance of different texture analysers. These texture analysers include Local Binary Patterns (LBP), Radial Density Profile (RDP), and respective variants of the two.

We implement the LBP feature extraction method in our Feed Forward Neural Networks and Random Forest Classifiers because a variant of it performs best among the texture measures used on virus images in \citet{kylberg2011virus}. With respect to \citet{kylberg2011virus} results, the first thing to note is the differences betwen ours and their preprocessing methods. \citet{kylberg2011virus} made modifications to the scales of their images. In one case, one pixel in the image corresponds to one nanometer, which they refer to as \emph{fixed scale}. In the other case, the radius of the virus is set to take twenty pixels, and they refer to this as \emph{object scale}. 

They implement a Random Forest classifier with 100 trees (we do the same for comparative purposes) and their results can be found in figure \ref{fig:relwork_results}. The results of six different texture extractors are shown in this figure, but our area of interest is the first row of results for LBP$^\textnormal{ri}$. $"ri"$ stands for rotational invariant and is a way to reduce the size of a feature vector by rotating a vector bitwise to get the smallest possible number (for e.g. the number 110 becomes 011). 
\begin{figure*}
	\centering
	\includegraphics[width=\linewidth]{images/boxes_results.png}
	\captionof{figure}{This figure comes from \citet{kylberg2011virus}. The classification errors are shown for a Random Forest classifier using the 6 different texture extractors as described in section \ref{text:relwork_results}. The boxes' vertical lines represent the median and the red $\times$ represent outliers that are at least 1.5 times the size of the box away from it. The error bars are from the lower to the upper quartile. We're only concerned with the first row of results for LBP$^\textnormal{ri}$.}
	\label{fig:relwork_results}
\end{figure*} 


\section{Methodology}

\subsection{Feature Design and Selection Methods}
We emulate one of the feature extraction methods found in \citet{kylberg2011virus}, Local Binary Patterns (LBP). LBPs work as follows:

Given an image, for each pixel $p_i$ in it we sample $n$ equally-spaced points on the circle of radius $r$ with center $p_i$ -- an example of sampling is shown in figure \ref{fig:lbp_basic} -- and construct a vector $v(p_i)$ such that its $i$th entry is a 1 if the $i$th sampled pixel has a value bigger than $p_i$, and 0 otherwise. 
\begin{Figure}
	\centering
	\includegraphics[width=0.5\linewidth]{images/lbp_basic.pdf}
	\captionof{figure}{Example of LBP sampling: The green points are the neighbouring sample points at distance $r$ from the central white point. In this case, we are sampling with $n=8$ neighbour points.}
	\label{fig:lbp_basic}
\end{Figure}
A sequence of 0s and 1s are constructed $v(p_i)$ to form a binary number $v_{p_i}$. Once we have the $v_{p_i}$ for all pixels, we construct a histogram counting the number of appearances of each value $v_{p_i}$. The histogram forms the feature vector associated with the given image. \citet{kylberg2011virus} denote this feature extraction method by LBP$_{n, r}$, where $n$ is the number of sampled points and $r$ is the radius, as described above. The resulting histogram is represented in a vector of counts with $2^n$ elements. 

\subsection{Dataset and Pre-Processing Methods}
\label{text:dataset}
The Virus Texture Dataset contains images (texture samples) of 15 virus types obtained through transmission electron microscopy (TEM). The texture samples are extracted using an automatic segmentation method used in \citet{JMI:JMI3556} that detects virus particles of various shapes in TEM using a series of analytical steps. Each virus class has 100 unique texture patches of size 41x41 pixels.

\begin{Figure}
	\centering
	\includegraphics[width=0.85\linewidth]{images/dataset_sample.png}
	\captionof{figure}{Example images from the Virus Texture Dataset, created by \citet{kylberg2011virus}.}
	\label{fig:lbp_basic}
\end{Figure}

The dataset is small for the purposes of improving our generalisation ability; we extend it by generating twelve random rotations for each image in the dataset, producing 18,000 more images.

\section{Baseline Classification Approach}
We tested Support Vector Machines (linear and radial basis kernels (rbf)), Logistic Regression, and Gaussian Naive Bayes using the scikit-learn \citet{scikit-learn} machine learning library. We use these classifiers as a baseline to provide insight into our datasets complexity. We trained and tested these classifiers over the rotated dataset. SVM with an rbf kernel performs the best since it allows for projection of the pixel feature space to a higher dimension, thus making it capable of capturing the non linearity of our data in a way that the other classifiers requiring linearly seperable data cannot. These classifiers clearly have poor results because none of them are specifically architected to handle images. See the appendix for the confusion matrices of the results.

\begin{center}
	\begin{tabular}{llc}
	\toprule
	\multicolumn{1}{c}{\textbf{Classifier}} & \textbf{Parameters} & \textbf{F1-Accuracy} \\ 
	\midrule
	Logistic Regression  & default         & 0.271 \\ 
	Linear 	SVM   	     & linear kernel   & 0.248 \\
	SVM                  & rbf kernel      & 0.327 \\
	Gaussian Naive \\Bayes & none            & 0.273 \\ \bottomrule
	\end{tabular}
\end{center}

\section{Random Forest Approach}
We tested several different Random Forest configurations when using LBP feature extraction on the rotated dataset. The results, while better than the baseline classifiers above, still have room for improvement. We obtained 43\% accuracy with 90 decision trees in the forest, which is less than what is obtained by \citet{kylberg2011virus}, who investigate more feature extraction methods than we do. 

\begin{Figure}
	\centering
	\includegraphics[width=1.0\linewidth]{images/random_forest_results.pdf}
	\captionof{figure}{Test-set results from random forest classification with default parameters.}
	\label{fig:random_forest}
\end{Figure}

Since our focus is not on Random Forest classification, and our results were far from optimal, we figured that futher hyperparameter optimization would not result in significant improvement. Implementing more complex cariants of LBP as described in \citet{kylberg2011virus} could improve our Random Forest classifier's results, although to truly mimic \citet{kylberg2011virus}'s results we would have had to use 16-bit images as opposed to 8-bit images.

\section{Neural Networks Approach}
We take inspiration from \citet{kylberg2011virus} again and use LBP features in a Feed Forward Neural Network (FFNN). Our FFNN is built using the Lasagne and Theano \citet{Bastien-Theano-2012, bergstra+al:2010-scipy} libraries. In our experiments, we used LBP$_{8,2}$, the default implementation of the \emph{Mahotas} computer vision library \citet{coelho2012mahotas}. The values of $8,2$ come from \citet{kylberg2011virus}, who achieve their best results with these parameters. \emph{Mahotas}' implementation of LBP is such that the feature vector is of smaller dimension than the usual dimension of a histogram with $2^N$ values where $N$ is the number of sampled points.

\subsection{Results}
To normalize the data, we chose to divide the entire dataset by 1.1 times the maximum value of a feature in the training set in order to be certain that no features in the normalized test set had a value greater than 1. In all cases, we use a learning rate of 0.005 and an L2 regularization weight of 0.0001, both arbitrarily chosen, and a 15 units softmax layer to conclude our network. The dataset described in section \ref{text:dataset} is shuffled, and the training is done with a batch size of 16 by stochastic gradient descent. All images pertaining to the results, such as the confusion matrices for the validation and testing set and the learning curves, can be found in the Appendix: the first neural network results are in figures \ref{shrine1_curves} and \ref{shrine1_mat}; the second neural network results are in figures \ref{shrine0_curves} and \ref{shrine0_mat}; the third nerual network results are found in figures \ref{shrine2_curves} and \ref{shrine2_mat}. The table below shows the results obtained on the test set. The first column represent, in order, the number of units in each of the hidden layers. 

\begin{center}
\begin{tabular}{lc}
\toprule
\multicolumn{1}{c}{\textbf{Hidden Layers}} & \textbf{Test Error} \\
\midrule
\textbf{256 units}                         &   52.77 \%          \\
\textbf{256 and 256 units}                 &   52.22 \%          \\
\textbf{256, 128 and 64 units}             &   51.94 \%       \\ \bottomrule
\end{tabular}
\end{center}

\subsection{Discussion}
 We notice that our neural network with one hidden layer took more time to converge than our three hidden layer network. The network with one hidden layer also had the largest error, and we think this is because the network did not have enough neurons to learn properly. Meanwhile, our network with three hidden layers was quick to overfit. This is to be expected since it had many more parameters to learn than the network with one layer. Nevertheless, our three hidden layer network gave the best results, and could be improved further by adding Gaussian noise to its neurons and applying dropout. 
\par Compared to the work of \citet{kylberg2011virus}, we can see from Figure \ref{fig:relwork_results} that the LBP$^{\textnormal{ri}}$ on fixed scale performed at about 30 \% error. whereas on the object scale it performed at about 63 \%. Since we didn't perform any rescaling of the images, we expect the error to be within that interval. On the other hand, resizing to fixed scale would certainly improve the accuracy. Finally, \emph{Mahotas}' implementation of LBP does not necessarily match the implementation of LBP$^{\textnormal{ri}}$ so this can induce some error as well.

\section{Convolutional Neural Network Approach}
CNNs are often used in image classification tasks as they possess the power of Feed Forward Neural Networks but are specifically structured to process images efficiently. As we approached the problem of virus classification from an image classification front, CNNs seemed a natural method to use.
Our CNN is built with the Lasagne and Theano \citet{Bastien-Theano-2012, bergstra+al:2010-scipy} libraries. Its first convolutional layer is fed by a 41x41 normalized input image. This layer consists of 16 8x8 filters, followed by a 2x2 max pooling layer. Two more convolutions are performed on top of this, the first with 48 5x5 filters, the second with 60 2x2 filters; both convolutions are fed into a 2x2 max pooling layer. Two fully connected layers with 50\% dropout on their inputs conclude the network. We used a learning rate of 0.005 and an L2 regularization weight of 0.0001, both arbitrarily chosen. Normalization was performed to place all pixel intensities between a range of 0 and 255. Training was performed with a batch size of 60 by stochastic gradient descent.

\subsection{Results}
Images pertaining to the results of our CNN can be found in figures \ref{cnn_cm} and \ref{cnn_plot} in the Appendix. The table below shows the best error costs found on our training, validation and test sets. 

\begin{center}
\begin{tabular}{cc}
\toprule
 \textbf{Best Train Error} 			& 0.0120 \% \\ 
 \textbf{Best Validation Error}     & 0.1500 \% \\  
 \textbf{Best Test Error} 			& 0.1511 \% \\ \bottomrule
\end{tabular}
\end{center}

\subsection{Discussion}

Our CNN classifies viruses on our training set with an accuracy of 85\%. Given that we passed in raw images to the network and still achieve nearly as high accuracy results as \citet{kylberg2011virus} highly optimized Random Forest, which obtained 87\%, it is clear that a highly optimized CNN would surpass their results for this problem. Our results might have been improved with a more exhaustive hyperparameter search. The search itself is computationally expensive as CNNs, and Neural Networks in general, have many parameters. Nevertheless, experimenting with the number of convolutional layers, percentage of dropout, learning rate etc seems a worthwhile investment.

From an medical perpsective, even 87\% accuracy is not high enough accuracy for the critical nature of this task; accuracy close to 100\% is desired, and an optimized CNN might achieve this. As it currently stands, however, this CNN could certainly be a constructive aid to medical professionals performing virus classification as a way to verify or inform their diagnoses.

\section{Reflection}
As discussed, due to the high performing nature of our CNN on classifying virus images obtained through microscopy techniques, this particular aspect of virus identification seems worth pursuing. Obtaining this type of data could be difficult, but as we've shown, the number of images obtained for any known virus can be extended with different pre-processing techniques, including rotations, embossing, and other additive noise measures. Clearly this represents a powerful aid for doctors and other members of the medical profession to inform and verify diagnostics. 
The nature of viruses is that they're constantly evolving, but we'd like to posit that machine learning methods for image classification are not limited to classifying known viral strains. \citet{work_A} showed sparse, tree-structured models could be learned from decision rules based on genetic subsequences that could predict viral hosts using discriminative machine learning tools. In this instance, the hosts of a novel virus can be determined even if it's remotely similar to a known viral host. It's a worthwhile endeavor to see if a CNN could be trained to predict unknown viruses in the context of training on a set of labeled viral strains from a family, and testing on a particular modified or evolved strain from the same family. 

\end{multicols}

\newpage
\section*{Appendix}
\appendix
\section{Baseline Classification Results}
\input{baseline_cms.tex}

\newpage
\section{Neural Network Trained on LBP Results} \label{appendix:images}
\input{shrine1_figures.tex}
\input{shrine0_figures.tex}
\input{shrine2_figures.tex}

\newpage
\section{Convolutional Neural Network Results}
\input{cnn_cm.tex}
\input{cnn_plot.tex}

\newpage
\begin{multicols}{2}
\paragraph*{} \lettrine[nindent=0em,lines=1]{\textit{W}}{}\textit{e hereby state that all the work presented in this report is that of the authors. }
\paragraph*{} Alan wrote the LBP explanations and \emph{Neural Network Approach}. Alan programmed the feed-forward neural network in \texttt{emerald.py} and extracted the Local Binary Patterns from the dataset via \texttt{purify\_dataset.py}. 
\par Kian created the rotated dataset and wrote its section \emph{Transformed Dataset}. He also wrote the \emph{Baseline Classification Approach} and \emph{Random Forest Approach} sections and programmed the baseline learners. 
\par Genevieve wrote the \emph{Introduction}, \emph{Problem Definition}, \emph{Convolutional Neural Network Approach} and \emph{Reflection} sections.
\par Alan and Genevieve wrote the \emph{Related Work} and \emph{Methodology} sections together. 
\par Genevieve programmed the CNN with help from Alan's \texttt{emerald.py}, and Kian helped debug. 

\bibliography{ref}
\bibliographystyle{plainnat}
\end{multicols}
\end{document}
