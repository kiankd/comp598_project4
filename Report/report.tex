\input{./preamble.tex}
\input{./title.tex}
\linespread{1.05}
\usepackage{lipsum}
\usepackage{multicol}
\usepackage{alltt}
\usepackage[margin=1in]{geometry}
\usepackage{mathtools}
% \usepackage{subcaption}
\usepackage{hyperref}
\usepackage{paralist}
\usepackage{float}
\usepackage{microtype}
\usepackage{abstract}
\usepackage[utf8]{inputenc}
\usepackage[numbers]{natbib}
\usepackage{graphicx}
\renewcommand{\abstractnamefont}{\large\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\itshape} % Set the abstract itself to small italic text
\usepackage{lettrine}
\usepackage{tabulary}
\usepackage{import}
\usepackage{makecell}
\usepackage{enumitem}
\usepackage{paralist}
\usepackage{pgf}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{breakurl}
\usepackage{cite}


\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}

\usepackage{titlesec} % Allows customization of titles
%\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
%\renewcommand\thesubsection{\Roman{subsection}} % Roman numerals for subsections
\titleformat{\section}[block]{\Large\scshape\centering\bfseries}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large\bfseries}{\thesubsection.}{1em}{} % Change the look of the section titles

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer
\fancyhead[C]{Virus Classification from Transmission Electron Microscopy $\bullet$ Fall 2015} % Custom header text
\fancyfoot[RO,LE]{\thepage} % Custom footer text

\title{\fontsize{18pt}{10pt}\textbf{Classifiying Transmission Electron Microscopy Virus Textures}} % Article title

% \author{
% \large{Alan Do-Omri}\\[2mm] % Your name
% \normalsize McGill University \\ % Your institution
% \normalsize \href{mailto:alan.do-omri@mail.mcgill.ca}{alan.do-omri@mail.mcgill.ca}}

\author{
\large{Alan Do-Omri}\\[2mm] 
\normalsize 260532985 \\ 
\and 
\large{Kian Kenyon-Dean}\\[2mm]
\normalsize 260564475 \\
\and
\large{Genevieve Fried}\\[2mm]
\normalsize 260564432 \\
}


\begin{document}

\maketitle

\begin{abstract}
On a daily basis doctors are tasked with determining the identity of viruses from blood samples. Even with advanced microscopy techniques, viruses can be difficult to discern by the expert human eye. Unfortunately, Misclassifying can have grave implications, not only for the patients in question but also for those who come into contact with him or her. Fortunately, virus classification is an image classification problem, and machine learning methods present exceedingly high accuracy rates for image classification tasks and don't require expert knowledge to do so. Here we present a successful application of Convolutional Neural Networks (CNN) to the problem of virus classification. Using the Virus Texture Dataset from Uppsala University, we classify viruses samples into one of 15 categories and compare its performance to previous work done on the same task.

\end{abstract} 
\vspace{0.5cm}

\begin{multicols}{2}
\section{Introduction}
Identifying viral pathogens, existing and emerging, is a critical priority for public health. Current diagnostic methods include direct examination of a speciman by an trained medical professional using Electron Microscopy methods. Unfortunately, even with magnification techniques it can be difficult for doctors to identify specific viral types. 

On the other hand, automatic classification methods in machine learning have proven quite successful at image classification. In particular, research employing neural networks has reshaped image classification in recent years \citet{Juergen_2015}. Specifically, Max Pooling Convolutional Neural Networks have set the bar at it's highest for an array of tasks, including the multi-digit number recognition in Google Street View images, reCAPTCHA box classification \citet{DBLP:journals/corr/GoodfellowBIAS13}, and ImageNet classification \citet{NIPS2012_4824}. 

The high degree of accuracy obtained with these automated methods is highly desirable for a problem like virus classification. In the desire to determine a model that accurately predicts known virus types, we treat the virus classification as an image classification problem. We use the Virus Texture Dataset from Uppsala University containing images of fifteen different virus types, which we extend through random rotations to enlarge our dataset. 

We experiment with an array of machine learning classifiers, including Support Vector Machines with linear and radial basis function kernels, Gaussian Naive Bayes, Logistic Regression, Random Forest Trees and Feed Forward Neural Networks with local binary pattern feature extractors. Our best results come from our Convolutional Neural Network (CNN)using max pooling, with which we classify virus samples from our dataset into one of 15 categories with an accuracy of approximately 85\%.\

\section{Problem Definition}

Our research takes place in a greater context of a desire to use machine learning classification methods to accurately classify viruses from viral sample images. This extends to both viruses which are currently known, and potentially evolved viruses like the H1N1 influenza pandemic virus in Mexico and the US in 2009, which was a modified version of known influenza strains. Convolutional Neural Networks with all the function approximation power of Neural Networks, but specifically architected for images, present a highly promising solution for computer automated virus identification, and a useful supplementation to traditional virology research. 

From our survey of the work done in virus classification, treating virus classification as an image classification problem is not common. Most researchers have used Support Vector Machines, tree modeling structures like Random Forests, and Feed Forward Neural Networks to classify and predict known and emerging viral strains through analysis of genome segments and genetic sequences \citet{work_A} \citet{work_B} \citet{work_C}. \citet{kylberg2011virus}, which we looked to for insight into feature extraction methods, use a Random Forest classifier to assess the discriminant potential of various texture measures on virus images. As far as we can tell, using a CNN is rather unprecedented for this problem. Thus we find the application of CNNs to virus classification a pertinent one that would be fruitful to explore further.


\section{Related Work}
In the work of \citet{kylberg2011virus}, texture analysis is performed on a dataset composed of 22 different  virus samples and the resulting feature vector is fed into a Random Forest classifier. The authors first compare the performance of different texture analysers. Included in their study were Local Binary Patterns (LBP), Radial Density Profile (RDP) and their respective variants, before proceeding to detail their results. 

We implement the LBP feature extraction method in our Feed Forward Neural Networks because a variant of it performs best among the texture measures used on virus images in \citet{kylberg2011virus}. With respect to \citet{kylberg2011virus} results, the first thing to note is the differences betwen our and their preprocessing methods. \citet{kylberg2011virus} made modifications to the scales of their images'. In one case, one pixel in the image corresponds to 1 nanometer, which they refer to as \emph{fixed scale}. In the other case, the radius of the virus is set to take 20 pixels, and they refer to this as \emph{object scale}. 

They implement a Random Forest classifier with 100 trees (we do the same for comparative purposes) and their results can be found in figure \ref{fig:relwork_results}. The results of six texture different texture extrators are shown in this figure, but our area of interest is the first row of results for LBP$^\textnormal{ri}$. ri signifies rotational invariant is a way to reduce the size of a feature vector by rotating a vector bitwise to get the smallest possible number (for e.g. the number 110 becomes 011). 
\begin{figure*}
	\centering
	\includegraphics[width=\linewidth]{images/boxes_results.png}
	\captionof{figure}{This figure comes from \citet{kylberg2011virus}. The classification errors are shown for a Random Forest classifier using the 6 different texture extractors as described in section \ref{text:relwork_results}. The boxes' vertical lines represent the median and the red $\times$ represent outliers that are at least 1.5 times the size of the box away from it. The error bars are from the lower to the upper quartile. We're only concerned with the first row of results for LBP$^\textnormal{ri}$.}
	\label{fig:relwork_results}
\end{figure*} 


\section{Methodology}

\subsection{Feature Design and Selection Methods}
We emulate one of the feature extraction methods found in \citet{kylberg2011virus}, Local Binary Patterns (LBP). LBPs work as follows:

Given an image, for each pixel $p_i$ in it we sample $n$ equally-spaced points on the circle of radius $r$ with center $p_i$ -- an example of sampling is shown in figure \ref{fig:lbp_basic} -- and construct a vector $v(p_i)$ such that its $i$th entry is a 1 if the $i$th sampled pixel has a value bigger than $p_i$ and 0 otherwise. 
\begin{Figure}
	\centering
	\includegraphics[width=0.5\linewidth]{images/lbp_basic.pdf}
	\captionof{figure}{Example of LBP sampling: The green points are the neighbouring sample points at distance $r$ from the central white point. In this case, we are sampling with $n=8$ neighbour points.}
	\label{fig:lbp_basic}
\end{Figure}
A sequence of 0s and 1s are constructed $v(p_i)$ to form a binary number $v_{p_i}$, hence the name. Once we have the $v_{p_i}$ for all pixels, we construct a histogram counting the number of appearances of each value $v_{p_i}$. The histogram forms the feature vector associated with the given image. \citet{kylberg2011virus} denote this feature extraction method by LBP$_{n, r}$, where $n$ is the number of sampled points and $r$ is the radius, as described above. The resulting histogram is represented in a vector of counts with $2^n$ elements. 

\subsection{Data and Pre-Processing Methods}
\label{text:dataset}
The Virus Texture Dataset contains images (texture samples) of 15 virus types obtained through transmission electron microscopy (TEM). The texture samples are extracted using an automatic segmentation method used in \citet{JMI:JMI3556} that detects virus particles of various shapes in TEM using a series of analytical steps. Each virus class has 100 unique texture patches of size 41x41 pixels. It is a rather small dataset for the purposes of our CNN so we chose to extend it by generating twelve random rotations for each image in the dataset, producing 18,000 more images.

\section{Baseline Classification Approach}
We tested 4 different classifiers using algorithms from the scikit-learn \citet{scikit-learn} machine learning library. These baseline classifiers provide results that help to reveal the dataset's complexity. We trained and tested these classifiers over the rotated dataset. Not surprisingly, the SVM with an rbf kernel performed the best since it allows projection of the pixel feature space to a higher dimension, thus making it capable of capturing aspects of the data that cannot be observed by the other classifiers. These classifiers clearly have poor results, but they provide a good baseline understanding of the dataset, showing that the image pixel space is not easily separable and requires a stronger non-linear function approximator in order to be properly understood. See the appendix for the confusion matrices of the results.

\begin{center}
	\begin{tabular}{llc}
	\toprule
	\multicolumn{1}{c}{\textbf{Classifier}} & \textbf{Parameters} & \textbf{F1-Accuracy} \\ 
	\midrule
	Logistic Regression  & default         & 0.271 \\ 
	Linear 	SVM   	     & linear kernel   & 0.248 \\
	SVM                  & rbf kernel      & 0.327 \\
	Gaussian Naive \\Bayes & none            & 0.273 \\ \bottomrule
	\end{tabular}
\end{center}

\section{Random Forest Approach}
We tested several different Random Forest configurations when using the LBP feature set on our rotated dataset. The results, while better than the baseline classifiers above, still have room for improvement. The best accuracy was about 43\% with 90 decision trees in the forest, which is less than \citet{kylberg2011virus}. 

\begin{Figure}
	\centering
	\includegraphics[width=1.0\linewidth]{images/random_forest_results.pdf}
	\captionof{figure}{Test-set results from random forest classification with default parameters.}
	\label{fig:random_forest}
\end{Figure}

Since this is far from optimal, we decided that cross-validation for hyperparameter optmization would not have resulted in significant improvement.  If we were attempting to mimic the results of \citet{kylberg2011virus}, we would have used their more complex feature extraction methods that they used to get $87\%$ accuracy with a Random Forest. Our results here show that more complex variants of LBP are necessary to use with a Random Forest classifier in order to get strong results, and they are similar to \citet{kylberg2011virus} since they got the best results using $100$ decision trees in the forest, which directly corresponds to the $90$ that we used. Additionally, the differences in results here may also be due to the fact that they did not use the extended dataset that we created; they used $100$ $16$-bit images per class, while we had $1200$ randomly rotated $8$-bit images per class.

\section{Neural Networks Approach}
In order to establish a baseline, we combine ideas from \citet{kylberg2011virus} and ourselves by attempting to use a neural network with the LBP features. Our neural networks are built using the Lasagne and Theano \cite{Bastien-Theano-2012, bergstra+al:2010-scipy} libraries. In our experiments, we will not rescale the images and we will use LBP$_{8,2}$, an implementation given by the \emph{Mahotas} computer vision library \citet{coelho2012mahotas}. We are not scaling the images because we are later comparing to CNNs, which will not use rescaled images. The values of $8,2$ come from the best values as checked by \citet{kylberg2011virus}. \emph{Mahotas}' implementation of LBP is done so that the feature vector is of smaller dimension than the usual dimension of a histogram with $2^N$ values where $N$ is the number of sampled points. This is achieved by some optimization on their end. 
\subsection{Results}
To normalize the data, we chose to divide the entire dataset by 1.1 times the maximum value of a feature in the training set in order to be more certain that no features in the normalized test set would have a value greater than 1. In all cases, we are using a learning rate of 0.005 and an L2 regularization weight of 0.0001, both arbitrarily chosen and the last layer was a 15 units softmax layer. The dataset described in section \ref{text:dataset} is shuffled and the training is done with a batch size of 16 by stochastic gradient descent. All images pertaining to the results such as the confusion matrices for the validation and testing set and the learning curves can be found in the Appendix: the first neural network results are found in figures \ref{shrine1_curves} and \ref{shrine1_mat}; the second neural network results are found in figures \ref{shrine0_curves} and \ref{shrine0_mat}; the third nerual network results are found in figures \ref{shrine2_curves} and \ref{shrine2_mat}. The table below shows the results obtained on the test set. The first column represent, in order, the number of units in each of the hidden layers. 

\begin{center}
\begin{tabular}{lc}
\toprule
\multicolumn{1}{c}{\textbf{Hidden Layers}} & \textbf{Test Error} \\
\midrule
\textbf{256 units}                         &   52.77 \%          \\
\textbf{256 and 256 units}                 &   52.22 \%          \\
\textbf{256, 128 and 64 units}             &   51.94 \%       \\ \bottomrule
\end{tabular}
\end{center}

\subsection{Discussion}
We had to stop the training of the one hidden layer neural network due to time constraints. We notice that the neural network with one hidden layer takes the longest time to converge whereas the one with three hidden layers took the shortest time. On the other hand, the network with three hidden layers overfitted the quickest. This is to be expected since it has many more parameters than the network with one layer. We also notice that the network with one hidden layer has the biggest error and we think this is because the network does not have enough neurons to learn properly. The three hidden layers network has too many neurons and is overfitting but we think its results can be improved by adding Gaussian noise to neurons and dropping out some of them. Nonetheless, it is still the network that gave the best results. 
\par Compared to the work of \citet{kylberg2011virus}, we can see from Figure \ref{fig:relwork_results} that the LBP$^{\textnormal{ri}}$ on fixed scale performed at about 30 \% error whereas on the object scale it performed at about 63 \%. Since we didn't perform any rescaling of the images, we expect the error to be within that interval. On the other hand, resizing to fixed scale would certainly improve the accuracy. Finally, \emph{Mahotas}' implementation of LBP does not necessarily match the implementation of LBP$^{\textnormal{ri}}$ so this can induce some error as well.
Chat Conversation End



\section{Convolutional Neural Network Approach}
CNNs are often used in image classification tasks as they possess the power of Feed Forward Neural Networks but are specifically structured to process images efficiently. As we approached the problem of virus classification from an image classification approach, CNNs seemed a natural method to use.
Our CNN is build with the Lasagne and Theano \cite{Bastien-Theano-2012, bergstra+al:2010-scipy} libraries. Our CNNs first convolutional layer is fed by a 41x41 normalized input image. This layer consists of 16 8x8 filters, followed by a 2x2 max pooling layer. Two more convolutions are performed on top of this, the first with 48 5x5 filters, the second with 60 2x2 filters; both convolutions are fed into a max pooling layer. Two fully connected layers with 50\% dropout on their inputs conclude the network. We used a learning rate of 0.005 and an L2 regularization weight of 0.0001, both arbitrarily chosen. Normalization was performed to place all pixel intensities between a range of 0 and 255. Training was performed with a batch size of 60 by stochastic gradient descent.

\subsection{Results}
Images pertaining to the results of our CNN in figures \ref{cnn_cm} and \ref{cnn_plot} in the Appendix. The table below shows the best error costs found on our training, validation and test sets. 

\begin{center}
\begin{tabular}{cc}
\toprule
 \textbf{Best Train Error} 			& 0.0120 \% \\ 
 \textbf{Best Validation Error}     & 0.1500 \% \\  
 \textbf{Best Test Error} 			& 0.1511 \% \\ \bottomrule
\end{tabular}
\end{center}

\subsection{Discussion}
Our CNN classifies viruses on our training set with an accuracy of 85\%. Due to the critical nature of the task, this is not as high as we had hoped for a standalone virus classifier, but certainly high enough to be a constructive aid to medical professionals performing virus classification (to verify or inform their diagnoses). Our results might have been improved with a more exhuastive hyperparameter search. The search itself is computationally expensive as CNNs, and Neural Networks in general, have many parameters. Nevertheless, experimenting with the nuber of convolutional layers, percentage of dropout, learning rate, to name a few, is a worthwhile investment given more time and effort. 

In addition, in the last few years several papers have shown that ensemble methods perform very well for reducing testing error \citet{chenlearning}. While it is not understood why ensembles of CNNs perform so well, using these methods in our classification task might improve performance.


\section{Reflection}
As discussed, due to the high performing nature of our CNN on classifying a virus from an image of it obtained through microscopy techniques, this particular aspect of virus identification seems worth pursuing. Obtaining this type of data could be difficult, but as we've shown, the number of images obtained for any known virus can be extended with different techniques, including rotations, embossing, and other additive noise measures. Clearly this represents a powerful aid for doctors and other members of the medical profession to inform and verify diagnostics. 
The nature of viruses is that they're constantly evolving, but we'd like to posit that machine learning methods for image classification are not just limited to classifying known virus strains. \citet{work_A} showed a sparse, tree-structured models could be learned from decision rules based on genetic subsequences for predicting viral hosts using discriminative machine learning tools. In this instance, the hosts of a novel virus can be determined even if it shares distant similarity with a known viral host.  It's a worthwhile endeavor to see if a CNN could be trained to predict unknown viruses in the context of training on a set of labelled viral strains from a family, and testing on a particular modified or evolved strain from the same family. 

\end{multicols}

\newpage
\section*{Appendix}
\appendix
\section{Baseline Classification Results}
\input{baseline_cms.tex}

\newpage
\section{Neural Network Trained on LBP Results} \label{appendix:images}
\input{shrine1_figures.tex}
\input{shrine0_figures.tex}
\input{shrine2_figures.tex}

\newpage
\section{Convolutional Neural Network Results}
\input{cnn_cm.tex}
\input{cnn_plot.tex}

\newpage
\begin{multicols}{2}
\paragraph*{} \lettrine[nindent=0em,lines=1]{\textit{W}}{}\textit{e hereby state that all the work presented in this report is that of the authors. }
\paragraph*{} Alan wrote the LBP explanations and \emph{Neural Network Approach}. Alan programmed the feed-forward neural network in \texttt{emerald.py} and extracted the Local Binary Patterns from the dataset in \texttt{purify\_dataset.py}. 
\par Kian created the rotated dataset and wrote its section \emph{Transformed Dataset}, programmed the baseline learners and wrote the content for \emph{Baseline Results} and \emph{Conclusion}. 
\par Genevieve wrote the \emph{Introduction}, \emph{Related Work}, \emph{Problem Definition} sections, and the results and discussion of CNN.
\par Genevieve and Kian programmed the CNN with help from Alan's \texttt{emerald.py}. 

\bibliography{ref}
\bibliographystyle{plainnat}
\end{multicols}
\end{document}
