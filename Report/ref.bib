@incollection{kylberg2011virus,
  title={Virus texture analysis using local binary patterns and radial density profiles},
  author={Kylberg, Gustaf and Uppstr{\"o}m, Mats and Sintorn, Ida-Maria},
  booktitle={Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications},
  pages={573--580},
  year={2011},
  publisher={Springer Berlin Heidelberg}
}

@article {JMI:JMI3556,
  author = {Kylberg, G. and Uppström, M. and Hedlund, K.-O. and Borgefors, G. and Sintorn, I.-M.},
  title = {Segmentation of virus particle candidates in transmission electron microscopy images},
  journal = {Journal of Microscopy},
  publisher = {Blackwell Publishing Ltd},
  issn = {1365-2818},
  url = {http://dx.doi.org/10.1111/j.1365-2818.2011.03556.x},
  doi = {10.1111/j.1365-2818.2011.03556.x},
  pages = {no--no},
  keywords = {Radial density profile, transmission electron microscopy, virus detection, virus segmentation},
  year = {2011},
}


@online{dataset_url,
    author = "Gustaf Kylberg",
    year = "2014",
    title = "Center for Image Analysis", 
    url = "http:google.ca"
}
@incollection{maenpaa2003multi,
  title={Multi-scale binary patterns for texture analysis},
  author={M{\"a}enp{\"a}{\"a}, Topi and Pietik{\"a}inen, Matti},
  booktitle={Image Analysis},
  pages={885--892},
  year={2003},
  publisher={Springer}
}

@article{coelho2012mahotas,
  title={Mahotas: Open source software for scriptable computer vision},
  author={Coelho, Luis Pedro},
  journal={arXiv preprint arXiv:1211.4907},
  year={2012}
}

@article{scikit-learn,
	 title={Scikit-learn: Machine Learning in {P}ython},
	  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
		           and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
				            and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
					             Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	   journal={Journal of Machine Learning Research},
	    volume={12},
	     pages={2825--2830},
	      year={2011}
}

@article{Juergen_2015,
  title={Deep learning in neural networks: An overview},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural Networks},
  volume={61},
  pages={85--117},
  year={2015},
  publisher={Elsevier}
}

@article{DBLP:journals/corr/GoodfellowBIAS13,
  author    = {Ian J. Goodfellow and
               Yaroslav Bulatov and
               Julian Ibarz and
               Sacha Arnoud and
               Vinay D. Shet},
  title     = {Multi-digit Number Recognition from Street View Imagery using Deep
               Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1312.6082},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.6082},
  timestamp = {Fri, 04 Dec 2015 12:23:11 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/GoodfellowBIAS13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{work_A,
  title={Identifying Hosts of Families of Viruses: A Machine Learning Approach},
  author={Raj, Anil and Dewar, Michael and Palacios, Gustavo and Rabadan, Raul and Wiggins, Christopher H},
  year={2011}
}

@article{work_B,
  title={Applying machine learning techniques to classify H1N1 viral strains occurring in 2009 flu pandemic},
  author={Attaluri, Pavan K and Zheng, Ximeng and Chen, Zhengxin and Lu, Guoqing},
  journal={BIOT-2009},
  volume={21},
  year={2009},
  publisher={Citeseer}
}

@inproceedings{work_C,
  title={Applying neural networks to classify influenza virus antigenic types and hosts},
  author={Attaluri, Pavan K and Chen, Zhengxin and Lu, Guoqing},
  booktitle={Computational Intelligence in Bioinformatics and Computational Biology (CIBCB), 2010 IEEE Symposium on},
  pages={1--6},
  year={2010},
  organization={IEEE}
}

@incollection{NIPS2012_4824,
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  author = {Alex Krizhevsky and Sutskever, Ilya and Geoffrey E. Hinton},
  booktitle = {Advances in Neural Information Processing Systems 25},
  editor = {F. Pereira and C.J.C. Burges and L. Bottou and K.Q. Weinberger},
  pages = {1097--1105},
  year = {2012},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}


@MISC{Bastien-Theano-2012,
        author = {Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Bergstra, James and Goodfellow, Ian J. and Bergeron, Arnaud and Bouchard, Nicolas and Bengio, Yoshua},
         title = {Theano: new features and speed improvements},
          year = {2012},
  howpublished = {Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop},
      abstract = {Theano is a linear algebra compiler that optimizes a user’s symbolically-speciﬁed
mathematical computations to produce efﬁcient low-level implementations. In
this paper, we present new features and efﬁciency improvements to Theano, and
benchmarks demonstrating Theano’s performance relative to Torch7, a recently
introduced machine learning library, and to RNNLM, a C++ library targeted at
recurrent neural networks.}
}

@INPROCEEDINGS{bergstra+al:2010-scipy,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation},
   abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy’s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and
functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates
them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6× to 7.5× faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the
CPU and between 6.5× and 44× faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}

